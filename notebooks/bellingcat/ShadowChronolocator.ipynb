{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0cMu05_q5XDy"
      },
      "outputs": [],
      "source": [
        "# @title Chronolocate a Shadow 📅 { display-mode: \"form\" }\n",
        "\n",
        "# @markdown ### ⬅️ Click to find possible times that match the below information\n",
        "\n",
        "# @markdown Estimate the angles to the sun (in degrees):\n",
        "min_elevation_angle = 60  # @param {type:\"number\"} In degrees\n",
        "max_elevation_angle = 70  # @param {type:\"number\"} In degrees\n",
        "\n",
        "min_azimuth_angle = 170  # @param {type:\"number\"} In degrees\n",
        "max_azimuth_angle = 180  # @param {type:\"number\"} In degrees\n",
        "\n",
        "\n",
        "latlon = \"40.7600000,-73.9840000\" # @param {type:\"string\"}\n",
        "year=2025  # @param {type:\"number\"}\n",
        "utc_offset = -5  # @param {type:\"number\"}\n",
        "dst=0  # @param {type:\"number\"}\n",
        "step_minutes = 15  # @param {type:\"number\"}\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "## Get the shadow data from sunearthtools\n",
        "data_url = f\"https://www.sunearthtools.com/tools/downloadFile.php?tableformat=3&point={latlon}&utc={utc_offset}&yearAT={year}&dstAT={dst}&step={step_minutes}&email=\"\n",
        "df = pd.read_csv(data_url, sep=';', na_values=['--'])\n",
        "\n",
        "\n",
        "## Create a new dataframe where each row corresponds to a time step\n",
        "\n",
        "# rename first column to date\n",
        "df.rename(columns={df.columns[0]: 'date'}, inplace=True)\n",
        "\n",
        "cols = df.columns[1:-1] # first column is date, last columns is empty\n",
        "\n",
        "# Create a new DataFrame with the desired structure\n",
        "new_df = pd.DataFrame(columns=['date','time', 'elevation', 'azimuth'])\n",
        "\n",
        "for i in range(0, len(cols), 2):\n",
        "    time = cols[i].split(' ')[1]  # Extract time from column name\n",
        "    elevation = df[cols[i]].values\n",
        "    azimuth = df[cols[i + 1]].values\n",
        "\n",
        "    # Create a temporary DataFrame for this time step\n",
        "    temp_df = pd.DataFrame({\n",
        "        'date': df['date'].values,\n",
        "        'time': [time] * len(df),\n",
        "        'elevation': elevation,\n",
        "        'azimuth': azimuth\n",
        "    })\n",
        "\n",
        "    # Append to the new DataFrame\n",
        "    dfs = [new_df, temp_df]\n",
        "    # Keep only DataFrames that are not empty and not all-NA\n",
        "    dfs = [df for df in dfs if not df.empty and not df.isna().all().all()]\n",
        "    if dfs:\n",
        "        new_df = pd.concat(dfs, ignore_index=True)\n",
        "    else:\n",
        "        new_df = pd.DataFrame()\n",
        "\n",
        "new_df.dropna(inplace=True)\n",
        "new_df.sort_values(by=['date', 'time'], inplace=True)\n",
        "\n",
        "\n",
        "## Filter the DataFrame based on azimuth and elevation\n",
        "filtered_df = new_df[\n",
        "    (new_df['azimuth'] >= min_azimuth_angle) &\n",
        "    (new_df['azimuth'] <= max_azimuth_angle) &\n",
        "    (new_df['elevation'] >= min_elevation_angle) &\n",
        "    (new_df['elevation'] <= max_elevation_angle)\n",
        "    ].copy()\n",
        "\n",
        "# Reset index for the filtered DataFrame\n",
        "filtered_df.reset_index(drop=True, inplace=True)\n",
        "filtered_df['date'] = pd.to_datetime(filtered_df['date'], format='%Y-%m-%d')\n",
        "\n",
        "# For each date find the min and the max time\n",
        "result_df = filtered_df.groupby('date').agg(\n",
        "    min_time=('time', 'min'),\n",
        "    max_time=('time', 'max')\n",
        ").reset_index()\n",
        "\n",
        "# For simple summary group by contiguous sets of dates\n",
        "result_df['day_delta'] = result_df['date'].diff().dt.days.fillna(1).astype(int)\n",
        "result_df['contiguous'] = (result_df['day_delta'] > 1).cumsum()\n",
        "\n",
        "result_summary = result_df.groupby(['contiguous']).agg(\n",
        "    min_date=('date', 'min'),\n",
        "    max_date=('date', 'max'),\n",
        "    min_time=('min_time', 'min'),\n",
        "    max_time=('max_time', 'max')\n",
        ").reset_index(drop=True)\n",
        "\n",
        "print(result_summary.to_string(index=False))"
      ]
    }
  ]
}